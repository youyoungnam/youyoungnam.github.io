---
title: randomforest 정리
categories: modeling
author_profile: true
---


---

## RandomForest 알고있는 내용 정리하기
---

**정리를 하는이유 모델을 그냥 가져다가 사용하지말고 어떠한 장점과 단점이 있는지도 알아야할 필요가 있다. 그래야지 데이터를 보고 이데이터는 randomforest가 좋을지 아니면 다른 모델이 좋을지 알 수 있을거 같다.**


----

### 데이터셋에 칼럼이 너무많을때 rf가 안좋은 이유

**randomforest 사용 할때 칼럼이 너무 많기 때문에 하나의 나무에 들어가는 칼럼들중에서 별로 도움이 안되는 칼럼이 너무 많이 들어갈 수 가 있다
다시말하면, boosting모델과 다른게 boosting모델 장점이 있다 우리 모델이 학습을 할때 알아서 피드백을 받으면서 어떤나무는 ~이렇게 학습했네?
음 이런부분에서 학습을 못했으니 나는 이부분을 학습해야겠네 하면서 피드백을 받으면서 나무를 만든다 어느정도 나무의 성능이 보장이된다.**

**하나의 나무에 단독적으로 randomforest는 진짜 random하게 나무를 만들기때문에 특정 나무에 점수가 별로 안나오는 나무가 만들어질 수 있음 그래서 특히 칼럼이 많을때**

**뭐가 문제냐면 이렇게 y값에 영향을 주지않는 칼럼이 매우 많을 수 가 있음 그런데 그냥 random하게 나무를 만들다 보니까 대부분의 나무들이 별로 도움이 안되는 수 있다.**

**대부분의 나무들에서 다양한 학습해가지고 다양성을 이용해서 우리모델 점수가 나오는게 randomforest인데 이렇게 칼럼이 많아버리면 별로 중요하지 않은 칼럼이 많다보니까 그럴때 손해를 많이본다 왜?**

---
###변수중요도
---

**별로 중요하지않은 칼럼이 많이 포함된 나무들이 많다보니까 학습을 잘 못하는 나무들이 너무 많이 생성이 된다.
그래서 몇개나무만 학습을 잘하고 대부분 나무들은 못하기 때문에 점수가 잘 안나온다 그런데 boosting모델은 뭐가 다르다? 
그래도 어느정도 도움이 되는 칼럼이 포함이된다 나무를 만들때 왜냐면 피드백을 받기때문에 그래서 boosting모델이 앞도적으로 잘나온다.**

---