---
title: Cat vs Dog - image-classification
categories: deeplearning_image
author_profile: true
---




**kaggle에 image 대회는 두 가지 방법으로 대회를 시작 할 수 있다고 했다. 첫번째는 이미지 파일들이 csv 파일 형태 두번째는 사진들을 가지고 있는 zip파일 형태 
이번에는 이미지 파일을 가지고있는 형태를 어떻게 모델에 학습 시키는지 해볼것이다.**


데이터는 kaggle에 있는 cat vs dog 데이터를 사용 할 것이다. 
https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data


### 경로 형태로 되어있는 이미지는 어떻게 볼 수 있을까? 

경로 형태로 되어있는 이미지를 볼 수 있는 방법은 여러가지 방법이 있지만 쉬운 방법은 from PIL import Image 를 사용해서 이미지 경로를 넣어주면 된다. 
array형태로는 못 본다. array형태로 보고 싶으면 matplotlib 라이브러리를 사용해야한다.

```python
from PIL import Image

Image.open("train/cat.3808.jpg")
>> 고양이 이미지
```

### 모델 에 넣기 위해서는

첫번째 머신러닝이나 딥러닝은 모델에 넣기 위해서는 이미지나 글이나 음성이나 다 수치화를 하고 넣어 줘야한다. 결국에 이미지도 숫자다. 픽셀별로 0~255를 가지고 있다.
두번째 모델에 넣는 데이터들의 차원의 수가 같아야한다. 만약 이게 다르다면 학습 할 수가없다  예를들자면 이미지들의 크기 즉, 이미지의 사이즈가 같아야한다.



모델에 넣기위해 데이터 프레임을 만들것이다 이 데이터 프레임에는 이미지 경로 그리고 이미지에 해당하는 정답값들을 만들어 줄것이다.

데이터프레임을 만든 이유는 Imagegernertor라는 라이브러리를 사용 하기 위함이다. 이 라이브러리를 사용하면 이미지들의 사이즈를 조절해주고 이미지들을 수치화를 해준다.


이미지 사이즈 조절할 때 만약 원래의 이미지 크기 보다 작게 만들면 그 이미지가 가지고 있는 정보를 잃는 것이다  예를들어 고화질이 였던 사진을 줄이면 정보가 날라가는거다.
머신러닝으로 따지면 데이터가 400개였는데 100개로 줄여진거다. 그렇다고 작은 이미지를 큰 사이즈로 늘린다고 해서 정보를 더 많이 얻는건 아니다. 억지로 가로세로를 늘린 거니까.



```python
# train 이미지 데이터를 다 가져 올 수 있다.
import glob 
# 하위 디렉토리를 접근 하는 방법 모든 데이터에 접근한다는 뜻으로 * 을 넣어준다 
glob.glob("train/*")


train = pd.DataFrame({"path": glob.glob("train/*")})
train 


# 정답값은 경로에 들어있는 사진 이름에서 가지고 오면 된다.
# target 정답값 컬럼 만들어주기 
train["target"] = train["path"].apply(lambda x: x.split("/")[1].split(".")[0])


# test 데이터도 똑같이 해주자 

test = pd.DataFrame({"path": glob.glob("test/*")})


# 위에서 언급했던 Imagegerator를 사용해보자. 
from keras.preprocessing.image import  ImageDataGenerator

idg = ImageDataGenerator()

train_generator = idg.flow_from_dataframe(train, x_col= "path", y_col="target", target_size= (100,100), bach_size=100)

test_generator = idg.flow_from_dataframe(test, x_col="path", y_col=None, target_size=(100, 100), batch_size=100, class_mode = None, shuffle= False)
```

#### imageDataGerator() 인자 설명 
    - 첫번째 인자에는 우리가 위에서 만들었던 데이터 프레임을 넣어주면 된다 
    - 두번째 인자는 이미지 경로 를 가지고 있는 컬럼을 넣어주면된다.
    - 세번째 인자는 정답 값을 넣어주면 된다.
    - 네번째 target_size는 이미지들의 사이즈를 조절 할 수 있다. 똑같은 사이즈로 바꿔준다 
    - 다섯번째 bach_size는 모델에 학습할 때 몇장씩 사진들을 학습 할 것인가 를 조절 하는 파라미터다.보통 2의 거듭제곱 32 64 128...이런식으로 넣어준다 
       - 부연설명 예를들어 모델에 모든 이미지 데이터 2만5천장을 넣어주고 학습을 하면은 문제가 생긴다.(만약에 사진사이즈가 작지않는 이상 처리를 할 수 없다.)
       왜 문제가 생길까? 이미지 한장당 차지하는 메모리(용량)이 너무 커서 RAM(램) 소모가 어마어마 하다. 그래서 이것을 2만5천장을 한번에 학습을 하는게 아니라 몇십장씩 끊어서 학습을 한다는것 
       - 위 코드를 설명 하자면 모든 이미지 데이터 사진들을 100 x100 맞추고 100장씩 학습을 한다(100장씩 학습을 한 후에는 학습한 100장은 버리고 다음 100장을 학습한다.) 이러면은 ram이 잘 터지지 않는다.  
       - 위에서는 batch_size를 100을 준이유는 테스트 해보기위해 



### 모델링(Modeling)

```python
from keras import Sequential
from keras.layers import *


model = Sequential()
model.add(Conv2D(32, (3,3), activation = "relu", input_shape= (100,100, 3))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(2, activation = "softmax"))
model.compile(optimizer = "adam", loss= "categorical_crossentropy", metrics = ["acc"])
model.fit(train_generator, epochs = 3)
```


## Conv2D(1, 2, 3, 4)파라미터 간단 설명
   - 1 번 파라미터 설명 
     32의 의미는 과연 몇가지의 특징을 추출할 것인가(머신러닝으로 따지면 columns의 개수이다.)모델이 알아서 이러한 특징을 추출하니까 고양이 강아지 세분화가 잘되는구나
     혼자 힘으로 알아서 판단한다. 
   - 2 번 파라미터
     (3,3)은 filter_size 간단하게 설명하면 하나의 이미지를 맨위 왼쪽부터 3,3인 필터가 오른쪽으로 움직이면서 사칙연산(나중에 따로 filter_size정리필요)


#### Model 평가하기 


```python
model.evaluate(test_generator)
result = model.predict(test_generator)
```



#### sub 파일을 제출할때 주의

**sub의 id값과 test_generator가 가지고 있는 값의 순서가 다르다 이 순서를 동일하게 해주는 작업이 필요.**


```python
sub["id"] = test_generator.filenames


sub["id"] = sub["id"].apply(lambda x : x.split("/")[1].split(".")[0])
sub


# csv 파일로 저장하기 
sub.to_csv("result1.csv", index= 0)

```
