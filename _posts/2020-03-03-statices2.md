---
title: 회귀분석이란
categories: 데이터분석
author_profile: true
---

### 회귀분석이란
* **지도학습(Supervised learning)**
  $Y=f(x)$에 대하여 입력변수x와 출력변수 y의 관계에 대하여 모델링 하는것 
  즉, y에 대하여 예측 혹은 분류하는 문제

  **회귀(Regression):** 입력변수 x에 대해서 연속형 변수 y를 예측

  **분류(Classification):** 입력변수 x에대해서 이산형 변수 출력 y(Class)를 예측


### 회귀분석
위에서 말했듯이 입력변수인 x의 정보를 활용하여 출력변수인 y를 예측하는 방법

회귀분석중 간단한 방법으로는 선형 회귀분석 이 있으며, 이를 바탕으로 더 복잡한 회귀분석이 가능

<img src="/assets/images/m5.png">

왼쪽이 선형회귀분석 오른쪽이 더복잡한 회귀분석 



$$Y = B_0 + B_1x+c$$
$B_0$는 절편, $B_1$은 기울기 $c$는 미지의 noise값

$${i~i, i, d N(0,분산^2), Y_i~N(B_0+B_1x_i,분산^2)}$$
Y_i 여기 부분은 정규분포를 따른다는 가정도 있다.

단순 선형 회귀분석

우리가 알고싶은식
$Y = B_0 + B_1x+c$

우리가 추정해야하는식
$$Y^` = B_0^` + B_1^`x$$

추정해야하는식에 있는 `이것은 추정 해야한다는 의미

---


### 어떻게 추정 할까??

여러개 직선중 가장 좋은 직선은 ? 3
<img src="/assets/images/a1.png">
왜 3번일까?? 
**1. 3번의 직선은 데이터 사이의 간격이 작기때문(오차가 작아서)** 
**2. 직선과 데이터의 차이가 평균적으로 가장 작아지는 직선** 
**3. 직선이 y를 가장 잘 설명 하고 있기때문**


---

**회귀계수추정**

- 실제값과 우리가 추정한 값의 차이가 작으면 적을수록 좋은것
- 실제값과 우리가 추정한값의 차이를(잔차(residual))라고 하며 이를 최소화 하는 방향으로 추정
- 잔차의 제곱합(SSE; Error Sum of Squares)


$e_i = (y_i-y_i^`)$
$$Sum(e_i)= e_1^2+e_2^2+e_3^2....e_n^2$$

**우리는 sse에 대해서 미분을 구한다음 기울기을 구하고 기울기가 0이 되는지점을 찾아서 $B_0^` B_1^`$을 찾을것 이다.**

e_i는 실제값과 우리가 추정한값을 빼준거다

굳이 잔차의 제곱시키는 이유 잔차의 합이 0이 되는 해는 무수히 많다. 잔차의 절대값의 합은 미분이 불가능 형태

**잔차의 제곱의합은 미분이 가능한 형태로 유일한 해를 찾을수 있음**

나중에 SSE B0, B1로 편미분하여 연립방정식을 푸는방법을 올릴것이다.


