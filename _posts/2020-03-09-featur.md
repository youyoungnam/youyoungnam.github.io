---
title:  변수 선택법 및 선형회귀 실습
categories: 데이터분석
author_profile: true
---

### 변수선택법
**모델 선택(변수 선택)**
**변수가 여러개일때, 최적의 변수조합을 찾아내는 기법 변수의 수가 n개일때 변수의 총 조합은 $2^n$으로 변수 수가 증가함에 따라 변수조합수는 기하 급수적으로 증가**

> - **변수가 n개면 총 조합은 $2^n$개**

**총 변수들의 조합중 최적의 조합을 찾기위해 차선의 방법**
*Optimale은 아님 Optimal한 조합을 찾는 방법은 모든 경우의 수 조합을 다 해보는것*

---

### 3가지 방법

- **1. Feed Forward selection방법**
   변수를 추가해가며 성능지표를 비교해가는 방법
   주로 **AIC**를 사용한다 다른걸 봐도 상관없음.
- **2.Backword Elimination방법**
   변수를 제거해가며 성능지표를 비교해가는 방법
- **Stepwise방법**
  가장 유의미한 변수를 차가하거나 유의하지 않는 변수를 제거해 나가는 방법 전진 선택법을 사용할때 한 변수가 선택디면 이미 선택된 변수중에 중요하지 않은 변수가 있을 수 있음
  전진 선택법의 각 단계에서 이미 선택된 변수들의 중요도를 다시 검사하여 중요하지 않은 변수를 제거하는 방법

  **일반적으로 쓰이는 방법**
  1. 변수입력/제거를 위한 P-value 임계치 설정
  2. Forward selection을 통한 변수 설정
  3. 선택된 변수중에 유의미한 변수를 남기고 제거, 2-3번반복
  4. 변수가 추가되거나 제거할 케이스가 없는경우 종료.
  

  ---


  ### 실습

여기서 사용되는 데이터는 캐글에있는 토요타데이터를 가지고 실습 해볼것이다.


[캐글데이터](https://www.kaggle.com/search?q=toyota+in%3Adatasets)


```python
import pandas as pd
import numpy as pd
import statsmodels.api as sm
from sklean.model_selection import train_test_split


corolla = pd.read_csv("ToyotaCorolla.csv")

corolla.head(2)

corolla.shape

nCar, vCar = corolla.shape

print("행:", nCar, "열:", vCar)
```
<img src="/assets/images/z.png">  

```python
#범주형 변수확인하기 
# 일단 어떤종류가 있는지 확인하자 

corolla.Fuel_Type.unique()
>> array(['Diesel', 'Petrol', 'CNG'], dtype=object)
# 범주형 변수가 3개가 있다. 이제 각각 이진형 변수로 바꿔줄것이다.

def dummy(data, ncar, types):
    dummy = np.repeat(0, ncar)# 행의 갯수만큼 0을 만들어줬다.
    idx = np.array(data.Fuel_Type == types)# 각 변수형이 있는곳에 true 없는곳에 False 형태로 만들어줬다
    
    dummy[idx] = 1 # True인곳에 1을 넣어줬다
    return dummy


petrol = dummy(corolla, nCar, "Petrol")
diesel = dummy(corolla, nCar, "Diesel")
cng = dummy(corolla, nCar, "CNG")

Fuel = DataFrame({"Petrol": petrol, "Diesel":diesel, "CNG": cng})

# 의미 없는 변수 제거


corolla_ = corolla.drop(['Id', 'Model', "Fuel_Type"], axis=1, inplace= False)

#  아까 만들어줬던 데이터프레임이랑 의미없는변수 제거한 데이터프레임이랑 합쳐준다.
mir_data = pd.concat((corolla_, Fuel), 1)

print(mir_data.head())
```

<img src="/assets/images/q1.png">


### 선형회귀시작

```python
# bias추가 
mir_data = sm.add_constant(mir_data, has_constant="add")
mir_data.head()
# 상수항을 왜 추가해줘야 하냐면 회귀분석을 하려면 상수항을 추가해야한다.


#데이터 분할

# 먼저 타깃 변수 분리
feature_columns = list(mir_data.columns.difference(["Price"]))
X= mir_data[feature_columns]
Y = mir_data.Price


train_x, test_x, train_y, test_y = train_test_split(X,Y, train_size= 0.7, test_size=0.3)

# 사이즈보기

print(train_x.shape, text_x.shape, train_y.shape, test_y.shape)

>> In [30]:




# 사이즈보기
​
print(train_x.shape, text_x.shape, train_y.shape, test_y.shape)
>> (1005, 37) (431, 37) (1005,) (431,)


## 회귀모델에 적합

full_model = sm.OLS(train_y, train_x)
fitted_full_model = full_model.fit()

# 확인

fitted_full_model.summary()
``` 
<img src="/assets/images/cz.png">


**$R^2$을 보니 0.915 높고 대부분 변수들의 유의한거같다 그리고 전체적으로 P-value가 낮은걸 볼 수 있는데 air_bag_2는 p-value가 높은걸 볼 수있다.**

### 다중공선성을 확인하자

```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif = pd.DataFrame()
vif["VIF Factor"] = [variance_inflation_factor(mir_data.values, i) for i in range(mir_data.shape[1])]
vif["Feature"] = mir_data.columns
```
<img src="/assets/images/zz.png">


다중공선성은 변수들간에 강한 선형관계가 있다고했다 그리고 보통 vif가 10이상이면 다중공선성이 있다~~ 라고 생각하면 된다.


### Correlation확인

```python
import matplotlib.pyplot as plt
import seaborn as sns

corr = mir_data.corr()

fig, ax = plt.subplots(figsize=(20, 20))
#Generate Heat Map, allow annotations and place floats in map
sns.heatmap(corr, cmap='magma', annot=True, fmt=".2f")
plt.xticks(range(len(corr.columns)), corr.columns);
#Apply yticks
plt.yticks(range(len(corr.columns)), corr.columns)
#show plot
plt.show()
```

```python

# 학습데이터 잔차 확인
res= fitted_full_model.resid

fig = sm.qqplot(res, fit=True, line="45")a

```
<img src="/assets/images/za.png">

**normal q-qplot 그릴수 있다 
normal q-qplot은 잔차가 얼마나 정규분포를 따르는지 본다고했다 잔차의 정규성을 확인하는거다 
그래프를 잘 보면 2~ 4사이 맨위 파란점 튀어나간거 랑 -4 ~-2사이 튀어나간것들 약간 정규성을 띄지 않는다고 볼 수있다 y=x형태여야지 정규성을 띈다고했다
사실, y=x는 진짜 이상적인 결과이고 실제데이터같은건 그렇게 되기가 힘들다 이렇게 꼬리부분이 이렇게 되어있는게 일반적이다
맨위에꺼 들만 없으면 엄청 잘된건데 ?.. 라고 할수있다 심한경우는 엄청 꼬불꼬불 할 수도 있다.**



```python
# residual pattern확인
pred_y = fitted_full_model.predict(train_x)
import matplotlib.pyplot as plt
fig = plt.scatter(pred_y,res, s=4)
plt.xlim(4000,30000)
plt.xlim(4000,30000)
plt.xlabel('Fitted values')
plt.ylabel('Residual')
```
<img src="/assets/images/aa.png">


```python

# 검증 데이터에 대한 예측을 해보자

pred_y2 = fitted_full_model.predict(text_x)

# 잔차 실제값과 예측값 차이 

plt.plot(np.array(test_y-pred_y2), label="pred_full")
plt.legend()
plt.show()
```

<img src="/assets/images/ab.png">


