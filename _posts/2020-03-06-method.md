---
title:  모형의 성능지표
categories: 데이터분석
author_profile: true
---

### MSE(Mean Squared Error)

**F(우리가추정하는것)가 제대로 추정되었는지 평가하기위해, 예측한값이 실제값과 유사한지 평가하는 척도**



$$ MSE = {{1\over n} \sum_{i=1}^n[y_i - \widehat{f}(x_i)]^2}$$

> - **$\widehat{f}(x_i)$: 우리가 추정해야 하는값**
> - **n: n개의 데이터**
> - **$y_i$: 실제값(실제 종속변수)**
> - **MSE는 실제 종속변수와 예측한 종속변수의 변수간의 차이 회귀분석에서는 MSE가 최소화 되게끔 구했다.**
MSE는 작으면 작을수록 좋지만, MSE를 과도하게 줄이면 과적합오류를 범할 가능성이 있다. 따라서 검증이 집합의 MSE를 줄이는 방향으로 f를 추정

---

### MAPE(Mean Absolve Percentage Error)

**F가 제대로 추정되었는지 평가하기 위해 예측한값이 실제값과 유사한지 평가하는 척도**

$$MAPE = {1000\over n} \sum_{i=1}^n|{{y_i} - \widehat{f}(x_i)\over y_i}|$$

**MAPE는 퍼센트값을 가지며 0의 가까울수록 회귀모형의 성능이 좋다고 할 수 있다. 0% ~ 100% 사이값을 가져야 이해하기 쉽다 성능비교 해석가능 주로 MSE사용**

---

### 정확도(Accuracy)
**정확도는 전체 데이터 중에서 모형으로 판단한값이 실제값과 부합하는 비율**

**분모는 전체데이터가 되고 분자는 모형의 실제 정상을 정상으로, 그리고 실제 이상을 이상으로 옳게 분류한 데이터이다.**


$$Accuracy = {옳게분류된데이터수\over 전체데이터의수}$$

---

### 정밀도(Precision), 재현율(Recall), 특이도(Specificity)


|예측가능한 클래스|
|---|---|

||정상|불량|
|---|---|---|
|정상|TN|FP|
|불량|FN|TP|




$$정밀도(Precision)= {옳게 분류된 불량데이터 수\over 불량으로 예측한 데이터}={TP\over FP+TP}$$


$$재현율(Recall)= {옳게 분류된 불량데이터 수\over 실제 불량 데이터의 수}={TP\over FN+TP}$$


$$특이도(Specificity)= {옳게 분류된 정상데이터 수\over 실제 정상 데이터의 수}={TN\over TN+FP}$$



> - **정밀도(Precision): 정밀도는 분류모형이 불량을 진단하기 위해 얼마나 잘 작동했는지 보여주는 지표**
> - **재현율(Recall): 재현율은 불량데이터중 실제 불량이라고 진단하는 제품의 비율**
> - **특이도(Specificity): 특이도는 분류모형이 정상을 진단하기위해 잘 작동하는지 보여주는 지표**

---

### G-mean,F1_Measure
- **실제 데이터의 대표족인 특성에는 불량데이터를 탐지하는것이 중요하다는 점과 이러한 불량 데이터는 매우 소수의 데이터라는점(Class imbbalanced문제)**

- **데이터 1000개중 불량데이터가 10개 나머지 990개는 정상데이터라고 가정했을때, 분류모형이 모든데이터를 정상 데이터라고만 예측해도 정확도는99%이며 만약 우연히 1개만 불량이라고 예측했는데 실제로 불량일 경우 정밀도 지표는 1이다.**

- **실제 데이터 특성상 정확도 보다는 제 1종오류와 제 2종오류중 성능이 나쁜쪽에 더 가중치를 주는 G-mean지표나 불량에 관여하는 지표인 정밀도와 재현율만 고려하는 F1_measure가 더 고려 해볼 수 있는 지표이다.**


$$G-mean = \sqrt {specificity - recall} = \sqrt{(1-\alpha)(1-B)} $$



$$F_1Measure = {2\over 1/precision + 1/recall}= 2*{precision*recall\over precision+recall}$$



---

### Roc Curve, AUC

- **가로축을 1-특이도(specificty) 세로축을 재현율(recall)로 하여 시각화 한 그래프를 ROC CURVE라고함 이떄 Roc curve의 면적을 AUC라고함**



<img src="/assets/images/c.png">

#### 그래프해석

- **1번이 Roc curve**
-  **2번 y=x**
- **3번 이상적인 그래프**

**1번 그래프가 y=x인 직선 2번쪽으로 붙어있으면 쓸모없는 모델이 되고 3번처럼 볼록 해지면 좋은 모델이다.**

**면적 검은색 부분 0~1사이값을 가진다 1에 가까울수록 좋은 성능지표이다 AUC는 전체면적인 1에 가까우면 가까울수록 좋은거다**

> - **AUC: 1에가까우면 가까울수록 좋다.**

**모델은 기본적으로 어떤 데이터에 대해서 out값을 확률값으로 내보낸다. 확률값 어떤특정값 이상이면 불량이다 이렇게 이야기할 기준값이 필요한데 그걸 threshhold라고 한다 보통 그 threshold값을 보통 0.5로 잡는데, class imbalanced 하면 threshold값이 낮아져야 한다. 그래야 F1_measure이나 G-Mean이나 성능지표들이 올라가게 된다 그런데 그 threshold값에 따라서 이 성능지표가 너무 달라지다 보니까 아 이게 평균적으로 얼마나 잘 맞는건가 에 대한 성능지표가 필요한거다 그래서 나온게 Roc Curve와 Auc이다.**

**Class imbalanced한경우 이걸 보안하기 위해서 다른 성능 지표를 봐야하는데 그게 G-mean과 F1_measure이다 G-mean 과 F1_measure에도 단점이 있는데 이게 확률적으로 얼마나 좋은 모델이냐에 대한 성능지표가 AUC이다.**




> - **F1_measure 높으면 높을수록 좋음**
> - **G_mean도 높으면 높을수록 좋음**
