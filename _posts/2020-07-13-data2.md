---
title: kaggle(Tip) regression편
categories: 데이터분석
author_profile: true
---


----
###**kaggle competition regression문제에서 조금 더 성능올리기**
----

**kaggle에 있는 housing price 데이터셋을 가지고 예를 들어보겠다.**

**kaggle notebook을 보다보면 어떤 사람은 코드를 쉽게 간결하게 짜서 모델 성능을 올리는 사람도 있고 어떤 사람은 어렵게 해서 성능을 올리는 사람이 있다.(내가 이해를 못한게 더 큰부분을 차지함)**

**쉽고 간결하게 코드를 짜서 비슷한 성능을 나오게 하거나 오히려 더 좋은 성능을 내게 하는 코드를 만들 수 없을까 라는 고민을 한다.**

**내가 공부한 방식을 여기다 만들 생각이다.**

-------


**train set과 test set을 불러오겠다.**
```python
import pandas as pd
import numpy as np

train = pd.read_csv("train.csv")
test  = pd.read_csv("test.csv")
```
**train set과 test set을 한번에 보고싶다면 display()을 사용하면된다.**
```python
display(train, test)
```

*일단 baseline을 만들어서 천천히 모델 성능을 올리자.*

```python
all_data = pd.concat([train, test])
all_data
```
**왜 train, test set을 all_data에 concat을 할까?
->>전처리를 한번에 해주기 위해서이다 train set 따로 test set하면 불편해서 한번에 묶고 처리해주고 마지막에 분리해주면 된다.**

*baseline을 만들어준다고 했으니 수치형 데이터로만 학습을 할것이다.*

```python
all_data= all_data[all_data.columns[all_data.dtypes != object]]
all_data
```

*학습할때 필요없는 데이터를 지우자. ID랑 SalePrice를 지운다.*

```python
all_data2 = all_data.drop(["Id", "SalePrice"], axis=1)
all_data2
```

*왜 axis=1를 해줬을까?*
*->>1이 열기준이기 때문에  0은 행기준*

### Data Preprocessing 데이터 전처리

**데이터 전처리하기전에 어떤 모델을 사용할지 정해야된다. tree계열모델?? 선형모델?? tree계열 모델을 선택하면 딱히 정규화나 표준화 를 해줄 필요가 없다. 왜??**
**--> tree모델이 학습하는 과정은 단순이 이런식으로 학습을 하기때문에 주자창에 당신의 차가 있나요? 예/아니요 당신의 차색은 무엇인가요? 하얀색/검은색/ 노란색 선택을 하면서 학습을 하기때문에 딱히 전처리를 안해줘도된다.**

**선형모델을 사용할경우 정규화가 필요하다 왜냐하면**
각 데이터들이 가지고 있는 데이터값이 차이가 크다면 모델이 학습할때 고민을 한다. 어떤 변수는 엄청중요한데 가지고 있는 값들이 작아서 별로 중요하게 생각 안할수 도 있다.즉, 변수들이 가지고 있는 값들의 범위가 크면 중요성을 제대로 파악 못할 수 도 있다.

**나는 여기서 randomforest모델을 사용할거라서 딱히 정규화를 할 필요가없다.**

```python
# 수치형변수들의 결측치가 있는지 확인 
# 있다면 all_data2= all_data2.fillna(-1)로 해주자
# train set과 test set을 분리하자
train2 = all_data2[:len(train)]
test2 = all_data2[len(train):]
train2.shape, test2.shape
```

**데이터를 분리해줬으니 학습을 시켜주자!!**
```python
from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_jobs=-1) # n_jobs는 학습을 빨리하기위해서
rf.fit(train2, train["SalePrice"])
result = rf.predict(test2)
```

*이렇게 간단한 baseline을 잡았다 baseline을 잡았으니 어떻게하면 성능을 올릴지 생각을 해보자.*

**성능을 쉽게 올리는방법은 모델에 새로운 데이터를 넣었을때 학습이 잘된다. ex)칼럼 변형 or 칼럼 추출 새로운 데이터를 넣는거다.**

*그래서 나는 위에서 수치형데이터만 학습했는데 이제는 categorical data도 같이 넣어서 학습을 시켜볼 생각이다.*

*위에있는 이코드는 주석 처리를 해주자.*
```python
# all_data= all_data[all_data.columns[all_data.dtypes != object]]
# all_data

# 이자리에 밑에 카테고리 형 변수를 전처리해준 코드를 넣는다.

# from sklearn.preprocessing import LabelEncoder
# le = LabelEncoder()
# # categorical data만 모아주고 labelencoder을 할 생각이다.
# for name in all_data.columns[all_data.dtypes == object]:
#     all_data[name] = le.fit_transform(all_data[name])
```
*그렇다면 카테고리형 변수들은 그대로 학습을 할 수 가없다. 모델에 넣기위해서는 전처리가 필요하다.*

```python
# 이코드들은 설명 하기위해 따로 빼서 한것.
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
# categorical data만 모아주고 labelencoder을 할 생각이다.
for name in all_data.columns[all_data.dtypes == object]:
    all_data[name] = le.fit_transform(all_data[name])
# 만약에 카테고리 변수들중에 결측치가 있다면
# 위 코드는 에러가 나올것이다.
# 그래서 어덯게 해주냐면 le.fit_transform(list(all_data[name]))
# all_data[name]을 list로 묶어주면 된다.
```
*위처럼 하면 카테고리형 데이터 변수들이 추가된다. 그리고 다시한번 run all을 눌러주면된다.*  

**새로운 데이터를 추가하면서 모델 성능을 향상시켰다. 그렇다면 또 어떻게 모델 성능을 좋게 만들 수 있을까??**

**---> target변수 분포 형태를 보자**