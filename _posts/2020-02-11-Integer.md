---
title: 정수인코딩(Integer Encoding)
categories: NLP
author_profile: true
---
## 정수 인코딩
**정수인코딩 이란 무엇일까?
그리고 왜 정수 인코딩을 해줘야 할까?**

*일단, 컴퓨터는 문자나 글보다 숫자를 더 선호한다. 그래서 우리가 가지고 있는 텍스트를 숫자로 바꿔줘야한다. 숫자로 바꿔주는 여러가지 기법들이 있는데 그중 하나가 정수 인코딩이다.*

> **정수인코딩:** 각 단어에 정수를 맵핑하는 작업

예를들어, 컴퓨터, 마우스, 키보드, 스피커 있을때 
컴퓨터에 1 마우스에 2 키보드에 3 스피커에 4 숫자를 부여한다.(부여하는 방식이 인덱스를 준다는 말)

부여하는 방식이 여러가지가 있는데 랜덤으로도 부여하지만 
보통 전처리 또는 빈도수가 높은 단어들만 사용하기 위해서 단어에 대한 빈도수 기준으로 정렬한뒤 부여하기도 한다.


- 1 단어집합(Vocabulary)을 만든다.
- 2 빈도수가 높은 순서대로 낮은 숫자를 부여한다.

**실습**
```python
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
text="A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain."

#문장 토큰화 수행 
text = sent_tokenize(text)

# 정제 작업과 단어 토큰화 진행

vocab = {} # 단어집합과 빈도수 기록
sentences = []
stop_words = stopwords.words("english")
for i in text:
    token = word_tokenize(i) # 문장토큰화가 된걸 또 토큰화함
    result = []
    for word in token:
        if word not in stop_words:
            if len(word) > 2: # 문자 길이가 2이상인것만
                result.append(word)

                if word not in vocab: # 단어집합 추가
                    vocab[word] = 0
                vocab[word] +=1 # 같은 단어가 존재하면 1씩증가
    sentences.append(result) 
print(sentences)
print(vocab)
```
**결과**
>[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]
> 
>{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}

**이제 빈도수가 높은 순으로 낮은 인덱스를 부여한다.**
```python
vocab_sorted = sorted(vocab.items(), key = lambda x: x[1], reverse= True)

word2index={}
i=0

for word, frequency in vocab_sorted:
    if frequency >1:
    i+=1
    word2index[word] = i
print(word2index)
```
> {'barber': 1, 'person': 2, 'huge': 3, 'secret': 4, 'kept': 5, 'word': 6, 'keeping': 7}

**낮은 인덱스가 빈도수가 높은것**

자연어 처리를 하다보면 텍스트 데이터를 모두 사용하기 보다는 빈도수가 높은 n개의 단어만 사용하고 싶을때가 있다.

그래서 상위 n개의 단어만 사용하고 싶다면

```python
vocab_size =5

word_freq= [w for w,f in word2index if f>= vocab_size+1]
# 빈도수가 낮으면 높은 인덱스를 가지니 인덱스가 높은 단어들만 남기고

for word in word_freq:
    del word2index[word]
# 그단어들을 반복문을 통해 지운다.
print(word2index)
```
>{'barber': 1, 'secret'

: 2, 'huge': 3, 'kept': 4, 'person': 5}

**사실 위에방법보다 좀더 쉬운 방법이 있다 바로 Counter를 사용하면 된다.**

### Counter

```python
from collections import Counter
print(sentences)
```
> [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]

Counter 을 사용하기 위해서 문장의 경계인 [ ]을 지워줘야한다.

지우는 방법이 두가지가 있는데 첫번째는 **이중 for문** 사용하기
```python
result = []
for word in sentences:
    for token in word:
        result.append(token)
print(result)
```
> ['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'Knew', 'Secret', 'The', 'Secret', 'Kept', 'huge', 'secret', 'Huge', 'secret', 'His', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'His', 'barber', 'kept', 'secret', 'But', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']

두번째 방법 
```python
words = sum(sentences, [])
print(words)
```
>['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']

이제 Counter을 사용할 수 있다.

```python
vocab = Counter(words)
print(vocab)
```
>Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})

**위에서 단어집합을 만들때는 여러 코드를 작성했지만 
Counter을 사용하면 쉽게 단어집합을 만들고 빈도수를 기록할 수 있다.**

또 빈도수가 높은 단어만 가져올수도 있다.

```python
vocab_size =5

vocab =vocab.most_common(vocab_size)
print(vocab)
```
>[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]



이제 빈도수 가 높은 순으로 낮은 인덱스을 부여하면 된다.
```python
word_to_index = {}
i=0
for w, f in vocab:
    i +=1
    word_to_index[w] = i
print(word_to_index)
```
>{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}






**위에 내용은 [딥러닝을 이용한 자연어처리 입문](https://wikidocs.net/book/2155) 여기서 공부한 내용을 쓴것이다.**
