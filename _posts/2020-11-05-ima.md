---
title: EfficientNetB0을 활용한 image classification
categories: kaggle
author_profile: true
---



### 데이터사용은 Kaggle invasive-species-monitoring을 사용





**데이터 가져오기**
**이미지 문제에서는 데이터를 읽어올 때 두가지 방식이 있다고 했는데 첫번째 이미지만 있을 때 두번째는 csv 파일 형식일 때 지금은 jpg로 되어있기 때문에 불러오는 방법이 다르다.
일단, label값을 unzip을 해주자.**

```python
!unzip "/kaggle/input/invasive-species-monitoring/train_labels.csv.zip"
>>
Archive:  /kaggle/input/invasive-species-monitoring/train_labels.csv.zip
  inflating: train_labels.csv        
   creating: __MACOSX/
  inflating: __MACOSX/._train_labels.csv
# label값 읽어오기 
train = pd.read_csv("./train_labels.csv")
train
```
<img src="/assets/images/cc1.PNG">




**train name 칼럼에 경로 붙여주기 붙여주는 이유는 밑에서 image_generator을 사용하기 위해서다**


```python
train["name"] = train["name"].apply(lambda x: "/kaggle/input/train/"+str(x)+".jpg")
train

```
<img src="/assets/images/cc2.PNG">


**glob는 train데이터의 이미지경로를 리스트에 넣어주는 라이브러리이다.**


```python
import glob
glob.glob("/kaggle/input/train/*")
>>
['/kaggle/input/train/170.jpg',
 '/kaggle/input/train/1879.jpg',
 '/kaggle/input/train/438.jpg',
 '/kaggle/input/train/2257.jpg',
 '/kaggle/input/train/1886.jpg',
 '/kaggle/input/train/1183.jpg',
 '/kaggle/input/train/968.jpg',
 '/kaggle/input/train/1024.jpg',
 '/kaggle/input/train/234.jpg',
 '/kaggle/input/train/2045.jpg',
 '/kaggle/input/train/1299.jpg',
 '/kaggle/input/train/458.jpg',
 '/kaggle/input/train/1556.jpg',
 '/kaggle/input/train/2210.jpg',
 '/kaggle/input/train/1885.jpg',
 '/kaggle/input/train/580.jpg',
 '/kaggle/input/train/510.jpg',
 .......
 ]


 # test 데이터도 똑같이

 test = pd.DataFrame({"path": glob.glob("/kaggle/input/test-1/*")})

train["invasive"] = train["invasive"].astype("str")
```


**train 데이터 분리 해주자**

```python
from sklearn.model_selection import train_test_split

# stratify를 해주는 이유는 예측값 즉, y값에 데이터 분포가 다르기때문이다. 즉, 데이터를 균일하게 학습을 해주기 위함이다. 
x_train, x_valid = train_test_split(train, test_size=0.15, random_state=42, stratify=train["invasive"])
```



**ImageDataGenerator사용하기**

```python
idg = ImageDataGenerator(horizontal_flip = True)
train_generator = idg.flow_from_dataframe(x_train, x_col="name", y_col="invasive", target_size=(300,300) ,batch_size=32)

valid_generator = idg.flow_from_dataframe(x_valid, x_col="name", y_col="invasive", target_size=(300,300) ,batch_size=32)

test_generator = idg.flow_from_dataframe(test, x_col="path", y_col=None, target_size=(300,300), batch_size=32, class_mode = None, shuffle= False)
```

### ImageDataFenerator(horizontal_flip =True)
   - 강아지 고양이 분류문제에서 train set에서 왼쪽만 보는 강아지사진들이 많았다고하자 우리 모델은 왼쪽만보는 사진을 학습을 한다 그렇다보니 test_Set에서 강아지인데도 오른쪽을 보고 있는 사진을 예측을 잘 못한다 
     왼쪽만 보는 강아지사진을 학습을 하니까 오른쪽을 보는 강아지 사진을 학습을 못한다 그래서 이것을 해결 하기위해서 
    kaggle이니까 데이터가 많다 그렇지만 현업에서 데이터가 많이 없을때가 많다 
    딥러닝같은경우 데이터를 생성할 수 있다. 변형 좌우반전 위아래반전 줌인 줌아웃 사진 회전 이동 여러가지 방식을 통해서 둘 다 강아지라고 학습을 시킨다 
    이 기법이 agumentation 이미지 생성 
    대회에서 가장많이 쓰는 방법 머신러닝에서 날짜데이터 추가하는것처럼 많이 사용한다. 결국 우리 모델이 다양한 정보를 학습 할 수 있도록, 특정 데이터에만 과적합 되는것을 방지 할 수 있다.


### idg.flow_from_dataframe(x_train, x_col="name", y_col="invasive", target_size=(300,300) ,batch_size=32)
    - target_size 즉 이미지들의 사이즈를 조절해주는 옵션이다. 
    - batch_size는 학습할 때 몇장씩 학습을 할것인가의 옵션이다.
    - 이미지 사이즈가 늘어날수록 batch_size는 줄여줘야한다.



**모델 설계**

```python
from keras import Sequential
from keras.layers import *
# efficientnet 설치
!pip install -U git+https://github.com/qubvel/efficientnet
from efficientnet.tfkeras import EfficientNetB1
from keras.optimizers import SGD, Adam
from keras.callbacks import EarlyStopping, ModelCheckpoint



es = EarlyStopping(patience=3)

mc = ModelCheckpoint("best.h5", save_best_only= True)
```


### EarlyStopping(patience=3)
   - patience=3의 의미는 3번은 참겠다는 이야기이다. 예를들어, loss값이 0.5 그다음이 0.7 이 나오면 patience 한번 차감 또 그다음 0.6 나왔지만 0.5보단 좋지는 않아서 
   두번 차감 그다음 0.51 여전히 0.5보다 좋지 않기때문에 여기서 학습이 끝난다.
   - 근데 만약에 3번까지 참고 loss값이 안좋아졌다가 다시 좋아지면 다시 시작한다.

   - 나중에 딥러닝할 때 값들이 많이 다를 수 있다 그럴땐 patience를 늘려주자 

### ModelCheckpoint('best.h5', save_best_only= True)
  - modelcheckpoint을 넣어준 이유는 가중치 최적의 가중치를 저장하는것이다 
  - 최적의 epoch이 7번째라고 가정해보자 그러면 우리모델은 10번째에서 학습이 끝날것이다 왜냐면 위에서 patience을 3번을 줬으니
  - 최적의 epoch은 7인데 3번을 참느라 모델이 갑자기 바뀔 수 있기때문에 이것을 방지 해주기 위해서
  - 그래서 최적의 epoch은 7인데 10번째 까지 학습을 하면서 결국 10번째 학습을 한 모델의 weight 값을 사용하게 된다 이것이 ModelCheckpoint를 사용하는 이유
  

```python
from sklearn.model_selection import StratifiedKFold


skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=42)

result = 0
for train_index , valid_index in skf.split(train, train["invasive"]):
    x_train = train.iloc[train_index]
    x_valid = train.iloc[valid_index]

    idg = ImageDataGenerator()
    # test데이터용
    idg2 = ImageDataGenerator()

    train_generator = idg.flow_from_dataframe(x_train, x_col="name", y_col="invasive", target_size=(300,300) ,batch_size=32)
    valid_generator = idg.flow_from_dataframe(x_valid, x_col="name", y_col="invasive", target_size=(300,300) ,batch_size=32) 
    # test 평가셋은 변하면안된다. 
    test_generator = idg2.flow_from_dataframe(test, x_col="path", y_col=None, target_size=(300,300), batch_size=32, class_mode = None, shuffle= False)
    
    
    es = EarlyStopping(patience=3)
    mc = ModelCheckpoint("best.h5", save_best_only= True)

    model = Sequential()
    model.add(EfficientNetB1(weights = "imagenet", include_top= False, pooling = "avg"))
    model.add(Dense(2, activation="softmax"))
    model.compile(metrics =["acc"], loss="categorical_crossentropy", optimizer=Adam(lr = 0.0001))
    model.fit(train_generator, validation_data = valid_generator,epochs=100, callbacks= [es,mc])
    # 최적의 weight을 저장은 하는 코드 단순히 넣어줬다고 자동으로 사용되는건 아니다 나중에 예측할때 사용해야한다
    model.load_weights("best.h5")
    result += model.predict(test_generator)/5 # 앙상블 효과 
>>
Found 1836 validated image filenames belonging to 2 classes.
Found 459 validated image filenames belonging to 2 classes.
Found 1531 validated image filenames.
Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5
27164672/27164032 [==============================] - 1s 0us/step
Epoch 1/100
 1/58 [..............................] - ETA: 0s - loss: 0.6204 - acc: 0.6875

```